# 书评:设计数据密集型应用程序

> 原文:[https://dev . to/henrikwarne/book-review-design-data-intensive-applications-2307](https://dev.to/henrikwarne/book-review-designing-data-intensive-applications-2307)

《设计数据密集型应用程序》是一本多么棒的书啊！它用清晰的语言、非常详细的内容和毫不含糊的方式涵盖了数据库和分布式系统。我特别喜欢作者 Martin Kleppmann，他非常了解这个理论，而且似乎对他描述的系统类型有很多实践经验。

[![](../Images/36ff16376749f5e9df3ab4e908beaaeb.png)T2】](https://henrikwarne1.files.wordpress.com/2019/07/dsc_1971.jpg)

这本书里有太多我需要学习的东西，所以我总结了每一章的要点，特别强调了我觉得最有趣的部分。

这本书有三个部分:数据系统的基础(第 1-4 章)，分布式数据(第 5-9 章)，和派生数据(第 10-12 章)。每章都以大量参考文献结尾(在 30 到 110 之间)。我真的很喜欢参考文献的混合——一些是 20 世纪 70 年代及以后的计算机科学论文，许多是各种博客文章。

### [](#1-foundations-of-data-systems)1。数据系统基础

定义可靠性、可扩展性和可维护性的介绍性章节。我特别喜欢 Twitter 如何向关注者发送推文的例子。关于响应时间也有一个很好的观点:当最终用户需要多个后端调用时，许多用户可能会经历延迟，即使只有一小部分请求很慢(尾部延迟放大)。

### [](#2-data-models-and-query-languages)2。数据模型和查询语言

本章讨论了众所周知的关系模型和文档模型(NoSQL)。LinkedIn 概要文件可以用 JSON 文档来表示，这是一个很好的例子——概要文件的树状结构非常适合用 JSON 来表示。然而，随着文档之间的数据变得更加互联，可能会出现问题(在 LinkedIn 的例子中:对公司和大学的引用，用户之间的推荐)。在文档模型中，连接从数据库转移到应用程序。

文档数据库有时被称为无模式数据库。这是不正确的，因为有一个隐含的模式。更好的理解方式是写时模式(数据库在存储值时强制模式)和读时模式(模式是隐式的，只有在读取数据时才被解释)。这类似于编程语言中的静态类型和动态类型。

接下来是对查询语言的讨论，用一个很好的例子来对比命令式查询(编程语言中的一个循环)和声明式查询(SQL 中的一个 SELECT 语句)。最后讨论了类似图形的数据模型(例如 Neo4J 所使用的)和用于该模型的各种查询语言。

### [](#3-storage-and-retrieval)3。存储和检索

这是我最喜欢的章节之一。我之前上过一门关于数据库的 MOOC 课程，但是它并没有过多地谈论数据库的内部。本章首先解释 LSM 树和 B 树是如何工作的。

##### LSM-树木

Kleppmann 首先用两行 bash 代码创建了一个简单的数据库。通过向文件追加一行(键后跟值)来存储键和值。要检索给定键的值，需要遍历文件，如果找到了键，就获取该值。写入一个现有的键仅仅意味着将新的一行追加到文件中。带有键和值的旧行保留在文件中。但是 get 函数只返回为给定键找到的最后一个值，所以旧行留在文件中没有关系。

这里的关键(哈哈)思想是，只追加到文件中会更快(而不是在文件中改变值)。然而，扫描整个文件来检索键值是很慢的。一种加速方法是保存一个单独的散列，它有一个指针指向文件中每个键的起始位置。然后，读取操作首先查找要使用的偏移量，然后从文件中的该位置开始读取。

接下来，我们假设文件中的所有行都是按键排序的。这些文件被称为*字符串排序表*，缩写为*表*。如果我们有许多在不同时间创建的文件，那么一个给定的键可能会出现在许多文件中。但是，该项的最新值是唯一的有效值，所有其他值都已过时(被新值取代)。我们可以将这些文件合并成一个文件，同时删除所有过时的行。这被称为压缩，因为所有的文件都是按键排序的，所以可以用与合并排序相同的方式有效地完成。

首先，如何创建已排序的文件？您维护一个内存中的树结构(比如红黑树或 AVL 树)，称为 *memtable* 。这保持了数据的有序，一旦树达到一定的大小(几兆字节)，它就作为一个新的表被写出来。添加或更改键的值仅仅意味着将它添加到 memtable 中(如果它已经存在，可能会覆盖它)。要查找一个键的值，首先在内存表中搜索，然后在最近的表中搜索，然后在下一个旧的表中搜索，依此类推。

这种类型的存储结构被称为*日志结构的合并树* (LSM 树)，并在例如 Cassandra 中使用。

##### [](#btrees)B 树

b 树是最广泛使用的索引结构(在传统的 SQL 数据库中使用)，与 LSM 树有很大的不同。b 树也保持键值对按键排序，以允许快速查找。然而，数据以固定大小的*块*(也称为*页*)存储在磁盘上，通常大小为 4 KB。要更改块中的值，需要写入整个块。通过使用指向子块的指针来创建树，其中键范围变得越来越具体，直到找到包含所需值的叶块。*分支因子*描述了一个父节点可以有多少个子节点。

大多数数据库都可以放入三层或四层的 B 树中，一个分支因子为 500 的 4 KB 数据块四级树最多可以存储 256 TB。B 树结构是由波音公司的鲁道夫·拜尔和爱德华·麦克赖特于 1970 年提出的。不清楚 B 代表什么-*波音*、*平衡*、*宽阔*、*浓密*和*拜耳*都是根据维基百科建议的。

LSM 树的写入速度通常更快，而 B 树的读取速度更快。但是，有几个因素会影响性能，本章接下来将讨论这些因素。描述了不同类型的优化，以及处理崩溃的策略，例如使用*预写日志* (WAL，也称为重做日志)。

##### [](#transactions-and-analytics)交易和分析

当数据库首次出现时，它们通常用于商业交易，例如销售或支付工资。即使数据库开始用于其他任务，事务这个术语仍然存在。

有两大类应用:在线事务处理(OLTP)和在线分析处理(OLAP)。OLTP 通常在面对最终用户时使用，并且交易量通常很小。OLAP 更多地用于数据仓库环境中，其中的查询可能会从数百万条记录中聚合值。OLAP 的数据库通常以星形模式组织。

有时，面向列的存储用于 OLAP 用例。当处理一列中的大量值时(例如求和或求平均值)，这可能更有效。本章有一个很好的例子，说明位图和游程编码是如何被用来压缩存储值的。

这一章很长，但很好。我在工作中使用过 MySQL 和 Cassandra，了解内部存储模型的不同非常有帮助。

### [](#4-encoding-and-evolution)4。编码和进化

*向后兼容性*–新代码可以读取旧代码写入的数据。*向前兼容*–旧代码可以读取新代码写的数据。两者都需要。当程序中的数据需要保存到文件中或通过网络发送时，需要以某种格式进行编码。

涵盖了三种类型的数据编码。第一种是特定于语言的格式，例如 java 的 *java.io.Serializable* ，或者 Python 的 *pickle* 。使用这种格式存在许多问题:安全性、版本、性能，以及它们与特定编程语言相关的事实。

接下来是标准化的文本编码，如 XML、JSON 和 CSV。他们也有自己的问题。例如，它们不支持二进制字符串(没有字符编码的字节序列)。JSON 不区分整数和浮点数，也不指定精度。CSV 是一种相当模糊的格式。比如逗号和换行符应该怎么处理？

最后，详细描述几种二进制编码格式:Thrift(最初来自脸书)、Protocol Buffers(最初来自 Google)和 Avro(最初来自 Hadoop 项目)。它们都有模式，并使用一些巧妙的技巧使编码紧凑。

### [](#5-replication)5。分身术

这是*分布式数据*部分的第一章。复制意味着相同的数据存储在多台机器上。复制的一些原因是:即使系统的某些部分出现故障也能继续工作(提高可用性)，使数据在地理上靠近用户(减少延迟)，以及通过从许多机器提供相同的数据来提高读取吞吐量。

涵盖了三种不同的模式:*单领袖*、*多领袖*和*无领袖*。复制可以是同步的，也可以是异步的。如果它是同步的，则主节点和所有从节点会在向用户确认写操作之前对其进行确认。如果任何一个从机速度慢或出现故障，这可以阻止所有写入。因此，异步复制更为常见。

复制有许多棘手的方面。第一个是当建立一个新的追随者。由于领导者中的数据不断变化，通常您会拍摄领导者数据库的一致快照，并将其复制到新的追随者中。然后，您需要处理在复制过程中发生的变更积压。

如果一个追随者失败了，它需要在恢复后迎头赶上。这意味着它需要跟踪在失败之前已经处理了来自领导者的哪些交易。如果领导者失败，需要选择新的领导者。这称为故障转移。这里很多事情都可能出错。如果使用异步复制，新的领导者可能没有收到所有的写入。如果在选择新的领导者后，以前的领导者重新加入群集，那些未复制的写入会发生什么情况？

执行复制也很棘手。如果使用 NOW()或 RAND()，简单地重复 SQL 语句会导致问题。还有许多其他的边缘情况，所以通常不使用这种方法。相反，使用数据库内部预写日志。这是一个只附加的字节序列，包含所有对数据库的写入。

##### [](#replication-lag)复制滞后

当您使用异步复制时，您将获得最终的一致性。即使复制延迟通常很小，一系列因素(例如网络问题或高负载)也会导致延迟达到几秒甚至几分钟。当您有复制延迟时，可能会出现几个问题:如果您提交数据，然后重新加载页面，您可能看不到刚刚写入的数据，如果重新加载的读取是从不同于接收写入的服务器完成的。对此有几种可能的解决方案，保证您**读取您自己的写入内容**。对于跨设备读取(从笔记本电脑更新，然后从手机读取)，这可能会更加棘手。

另一个异常是当时间倒流时。第一次读取返回用户 X 最近做出的评论。当刷新页面时，读取来自另一个(滞后的)服务器，用户 X 的评论尚未做出。**单调读取**是避免这种情况的一种方式，例如通过将所有读取路由到同一服务器。如果最终的一致性太弱，可以使用分布式事务。

##### [](#multileader-replication)多领导复制

在多数据中心操作中，使用多领导者复制是有意义的。有几个优点:性能(写入不必都经过单个领导者)、对数据中心中断的容忍、对网络问题的容忍(临时问题不会阻止写入通过)。然而，对于一个以上的领导者，存在**写冲突**的风险。有几种方法可以处理这些问题:最后一次写入获胜(基于时间戳或唯一 id)，自动将值合并在一起，或者保留冲突的值，让用户选择要保留的值。

##### [](#leaderless-replication)无领导复制

迪纳摩，卡珊德拉，Riak，伏地魔都是用无领导复制。为了确保没有写入丢失，并且没有读取返回过时值，使用了仲裁读取和写入。如果有 n 个副本，那么每次写入都必须由 w 个节点确认才能成功，每次读取都必须查询至少 r 个节点。只要 w + r > n，我们就期望在读取时得到最新的值。最简单的情况，n=3，w=2，r=2。但是，仍可能存在边缘情况，例如，如果写操作与读操作同时进行，则写操作可能只出现在某些副本中，并且不清楚是否应该为读操作返回新值或旧值。

如果某个节点已经关闭，并且有过时的值，那么在从该节点读取值时可以检测到它。这可以启动修复。也可以有一个反熵过程在后台运行，寻找不一致并启动修复。

这一章以一个很好的例子结束，说明了如何使用版本向量来跟踪并发事件之间的因果依赖关系。

### [](#6-partitioning)6。分割

将数据分成分区(也称为分片)的原因是可伸缩性。请注意，您可以同时进行分区和复制，每个分区都可以复制到几个节点上。每一段数据恰好属于一个分区。可以在键范围上或者通过键的散列来进行划分。如果某些分区的命中率高于其他分区(不平衡的工作负载)，分区的优势可能会丧失。对于分区数据库，辅助索引可能会变得很棘手。处理这种情况的一种方法是分散/聚集。

随着数据的增长和变化，可能需要重新平衡，即将负载从一个节点转移到另一个节点。不应移动不必要的数据。比如简单的用 *hash mod N* 会导致改动太多。更好的方法是使用比节点多得多的分区，并且只在节点之间移动整个分区。如果自动进行重新平衡，则存在级联故障的风险。因此，最好只手动操作。将请求路由到正确的分区通常由单独的协调服务来处理，比如 Zookeeper。

### [](#7-transactions)7。处理

本章介绍单台机器上的事务。事务将写入和读取分组到一个逻辑单元中。事务作为一个整体要么成功(*提交*)要么失败(*中止，回滚*)。这使应用程序开发人员不必处理许多不同的潜在问题:与数据库的连接丢失，数据库或应用程序在所有数据写入之前崩溃，几个客户端可能会覆盖彼此的数据等。

酸代表*原子数*、*稠度*、*隔离度*和*耐久性*。原子性与并发性无关(隔离才是)。相反，这意味着要么所有写入都成功，要么都不成功。没有部分写入的数据。一致性意味着不变量在事务前后必须始终为真。例如，所有账户的贷方和借方总是平衡的。数据库可以检查一些不变量，比如外键约束和唯一性约束。但一般来说，只有应用程序可以定义什么是有效的或无效的数据——数据库只存储数据。

隔离意味着并发执行的事务不会互相干扰。其余章节的大部分都涉及到这一点。最后，持久性意味着已经成功写入的数据不会丢失。然而，即使数据被写入磁盘，也有许多方式可能会丢失:磁盘可能会损坏，固件错误可能会阻止您的读取，机器可能会死机并阻止获取数据，即使数据在磁盘上是完好的。

##### [](#isolation-levels)隔离等级

当多个客户机同时读取和更新数据时，会出现数量惊人的陷阱。为了避免这些，有几个*隔离级别*来防止问题。

最基本的层次是**读提交**。这意味着在读取时，您只会看到已提交的数据，而不是正在写入但尚未提交的数据。当写入数据库时，您将只覆盖已经提交的数据。这也称为无脏读和无脏写。

**快照隔离**处理不同部分之间的一致性。如果你有两个账户，每个账户都有 500 美元，你从第一个账户读取余额，然后从第二个账户读取余额(两个账户都在同一笔交易中读取)，它们的总和应该是 1000 美元。但是，在第一次和第二次读取之间，可能会有一个并发事务将$100 从第二个帐户转移到第一个帐户。因此，第一次读取可能给出 500 美元，而第二次读取返回 400 美元(因为这里已经减去了 100 美元)。如果我们再次重复相同的帐户读取，我们将在第一次中获得 600 美元，在第二次中获得 400 美元，所以现在它们的总和是 1000 美元，正如预期的那样。如果避免了和变化的问题，就称为快照隔离，也称为**可重复读取**。

问题是，我们希望在给定时间点在数据库中看到的内容是一致的。我们不想看到上面例子中总数只有 900 美元的情况。例如，在进行备份时，这一点非常重要。制作备份可能需要几个小时，而且数据会不断变化，但我们希望备份中存储的内容保持一致。长时间运行的查询也是如此——我们希望它们在一致的快照上执行。常见的解决方案是使用*多版本并发控制* (MVCC)。数据库可以保存一个对象的几个不同的提交版本，因为各种进行中的事务可能需要查看数据库在不同时间点的状态。

当两个事务都写入数据时，存在**丢失更新**的风险。例如，如果两个用户同时读取一个计数器，递增它，并写回结果，则最终的计数器值可能只更新了一个，而不是两个。如果一个事务读取一些信息，根据这些信息做出决定，然后写入结果，那么可能会出现**写偏斜**。这意味着当结果写出来的时候，它所基于的前提已经不存在了。例如，试图避免重复预订的会议室预订系统。

##### [](#serializable-transactions)可序列化的事务

避免问题的一个可靠方法是，所有的事务都按顺序进行。然而，通常性能受到太多的影响。在某些情况下，您实际上可以串行执行所有事务**。您需要将整个数据集存储在内存中，并使用存储过程来避免事务期间的网络往返，并且吞吐量必须足够低，以便由单个 CPU 处理。**

 **大约 30 年来，唯一广泛使用的可串行化算法是**两阶段锁定(2PL)** 。广泛的锁定意味着吞吐量受到影响。也很容易出现死锁。一种称为可序列化快照隔离(SSI)的新算法也可以提供可序列化性，但由于乐观并发控制而具有更好的性能，这与 2PL 使用的悲观并发控制相反。

### [](#8-the-trouble-with-distributed-systems)8。分布式系统的问题是

这是我在书中最喜欢的另一章(连同第三章，存储和检索)。尽管我从事分布式系统和并发性问题已经有很长时间了，但是这一章还是让我大开眼界，因为所有的事情都有可能出错。

**不可靠的网络**。节点之间的连接可能会以各种方式失败。除了正常的故障模式之外，还列出了一些不常见的故障模式:交换机的软件升级导致所有网络数据包延迟超过一分钟，鲨鱼撕咬并损坏海底电缆，所有入站数据包都被丢弃，但出站数据包发送成功。即使在受控环境中，例如一个数据中心，网络问题也很常见。一项研究显示每月有 12 次网络故障。检测网络问题的唯一解决方案是超时。

**不可靠的时钟**。时间时钟根据某个日历返回当前日期和时间。它们通常与 NTP 同步。因为机器上的本地时钟可能会漂移，所以它可能会比 NTP 时间提前，重置会使它看起来像是跳回了过去。单调时钟更适合于测量经过的时间——它们保证总是向前移动。

即使使用 NTP 来同步不同的机器，也有许多可能的问题。由于存在来自 NTP 服务器的网络延迟，时钟的精确度是有限的。闰秒也导致了许多大面积停电。这些问题和其他问题意味着一天可能没有 86，400 秒，时钟可以向后移动，一个节点上的时间可能与另一个节点上的时间完全不同。此外，不正确的时钟很容易被忽视。

依靠时间戳来排序事件，例如 Cassandra 中的最后一次写入成功，可能会导致意想不到的结果。Google 的 Spanner 使用的一个解决方案是为时间戳设置置信区间，并确保在排序事件时没有重叠。

**流程暂停**。另一个与时间相关的问题是进程暂停。检查当前时间，然后采取某个操作的代码在采取该操作之前可能已经暂停了许多秒。发生这种情况的方式有很多:垃圾收集、从代码中看不出来的同步磁盘访问(Java classloader 延迟加载类文件)、操作系统交换到磁盘(分页)等。

为了在分布式系统中处理这些不同的问题，真理是由大多数人来定义的(下一章将详细介绍)。这里描述的可能问题会导致一些非常棘手的情况。更糟糕的是，如果参与节点故意试图制造问题。那叫做**拜占庭式的断层**，但这不在本书涵盖范围之内。通过控制所有相关的服务器，可以避免这些问题。

本章最后定义了*安全性*和*活性*。安全性意味着不会发生任何不好的事情(例如，错误的数据不会写入数据库)，活性意味着最终会发生一些好的事情(例如，在一个领导者节点失败后，最终会选出一个新的领导者)。

### [](#9-consistency-and-consensus)9。一致性和共识

分布式一致性主要是在面临延迟和故障时协调副本的状态。

##### [](#linearizability)线性化

线性化意味着复制的数据看起来好像只有一个数据副本，所有操作看起来都是原子地作用于数据(您看不到新旧值之间的值翻转)。它使数据库表现得像单线程程序中的一个变量。问题是它很慢，尤其是当网络延迟很大的时候。

上限定理有时表示为*一致性、可用性、分区容差*:从 3 个中选择 2 个。但是网络分区是一个错误，所以你没有选择，它会发生。Kleppmann 认为这个定理最好表述为:要么一致，要么分区时可用。他还指出，CAP 定理只谈到了分区，而没有谈到其他故障，如网络延迟或死节点。所以 CAP 定理不是那么有用。

##### [](#ordering-guarantees)订货保证

一个*全序*允许任意两个元素进行比较，你总能说出哪个更大。可线性化系统有一个全阶。如果两个事件同时发生，你不能说哪个先发生。这导致*因果关系*的一致性模型更弱。它定义了一个*偏序*:一些操作相对于彼此是有序的，但是一些是不可比的(并发的)。

Lamport 时间戳提供了与因果关系一致的总排序。然而，对于确保所选用户名的唯一性这样的问题来说，这还不够(如果两个用户同时尝试选择同一个用户名，我们只能在事后知道谁得到了它)。这导致**总订单广播**。它要求没有消息丢失；如果消息被传递到一个节点，它将被传递到所有节点。它还要求消息以相同的顺序传递到每个节点。拥有总订单广播可以实现正确的数据库复制。

##### [](#distributed-transactions-and-consensus)分布式事务和共识

对于分布式事务，可以使用*两阶段提交(2PC)* 。它需要一个协调员。首先，它向每个节点发送一个*准备*消息。节点检查它们是否能够执行写入，如果能够，它们回答是。如果所有节点回答是，下一个消息是*提交*。然后，每个节点都必须执行写操作。

有了单个领导者数据库，所有的决定都由领导者做出，因此你可以有可线性化的操作、唯一性约束、完全有序的复制日志等等(这些属性都可以简化为一致性)。如果领导者失败，或者网络问题阻止您联系它，有三种选择:等待它恢复，通过让人类选择新领导者来手动故障转移，或者使用算法自动选择新领导者。像 ZooKeeper 和 etcd 这样的工具在这方面有所帮助。

然而，并不是所有的系统都需要共识。无领导和多领导复制系统通常不需要。相反，他们必须处理发生的冲突。对我来说，这是最难理解的一章(我甚至不确定我是否完全理解了)，尤其是对共识是如何被简化为这些其他属性的解释。

### [](#10-batch-processing)10。成批处理

这是本书处理派生数据部分的第一章。记录系统(保存数据的权威版本)和衍生数据系统之间存在区别。派生数据系统中的数据是以某种方式转换或处理的现有数据，例如缓存或搜索索引。

本章以一个使用 Unix 工具进行批处理的例子开始。为了从访问日志中找到五个最流行的 URL，命令 *sort* 、 *awk* 、 *uniq* 和 *head* 被连接在一起。Sort 其实比我想象的强大很多。如果数据集不适合内存，它将自动存储到磁盘，并在多个 CPU 内核(如果可用)之间自动并行排序。

MapReduce 的工作方式和管道连接的 Unix 工具的工作方式有相似之处。它们不修改输入，除了产生输出之外，它们没有任何副作用，并且文件以连续的方式写入一次。对于 Unix 工具，*标准输入*和*标准输出*是输入和输出。MapReduce 作业在分布式文件系统上读写文件。由于输入是不可变的，并且没有副作用，失败的 MapReduce 作业可以再次运行。根据我们希望从 MapReduce 作业中得到的结果，可以执行一些不同种类的连接:排序合并连接、广播散列连接和分区散列连接。

使用管道 Unix 命令的类比，MapReduce 就像将每个命令的输出写到一个临时文件中。有更新的数据流引擎，如 Flink，可以提高传统 MapReduce 的性能。例如，通过不频繁地存储到文件(*具体化*)，以及通过仅在需要时排序，而不是在每个阶段。当在一些步骤中避免排序时，您也不需要整个数据集，并且您可以将这些阶段流水线化。

### [](#11-stream-processing)11。流处理

事件是一个小的、独立的、不可变的对象，包含在某个时间点发生的事情的细节。例如，事件可以由用户在网页上采取的行动、来自传感器的温度测量值、服务器指标(如 CPU 利用率)或股票价格生成。流处理类似于批处理，但它是在无界流上连续进行的，而不是在固定大小的输入上。在这个类比中，消息代理是文件系统的流等价物。

有两大类消息代理，这取决于它们是丢弃还是保留处理后的消息。基于日志的消息代理(如 Kafka)保存消息，因此可以返回和重读旧消息。这类似于数据库中的复制日志和日志结构存储引擎。

将对数据库的写入看作一个流也是有用的。日志压缩可以减少所需的存储，同时仍然允许流保留数据库的完整副本。将数据库表示为流允许派生的数据系统，如搜索索引、缓存和分析系统不断更新。这是通过使用变更日志并将它们应用到派生系统来完成的。也可以从头开始创建新的视图，并使用到目前为止的所有事件。这也非常类似于事件采购。

通常每个事件都有一个时间戳。这个时间戳不同于服务器处理事件的时间，这会导致一些奇怪的情况。例如，用户发出一个 web 请求，由 web 服务器 a 处理。然后用户发出另一个请求，由 web 服务器 B 处理。两个 web 服务器都发出事件，但 B 的事件先到达消息代理(可能是由于排队或网络故障)。因此，消息代理看到来自 B 的事件，然后是来自 A 的事件，尽管它们发生的顺序相反。

您还可以对流执行分析。例如，测量某事物的速率、计算某一时间段内的移动平均值，或者将当前统计数据与之前的时间间隔进行比较以检测趋势。可以使用各种类型的窗口:翻滚、跳跃、滑动或会话。此外，就像批处理作业一样，您可以将流数据与数据库表连接起来，以丰富事件数据。

### [](#12-the-future-of-data-systems)12。数据系统的未来

在这一章中，Kleppmann 描述了他对数据系统应该如何设计的设想。它基于第 11 章的思想，使用来自记录系统的事件流来创建数据的各种派生视图。由于派生是异步和松散耦合的，一个领域的问题不会像在紧密集成的系统中那样传播到其他不相关的领域。此外，这些类型的系统可以更好地处理错误。如果处理数据的代码有错误，可以修复该错误，然后可以重新处理数据。

还讨论了内部措施(如事务)如何不足以防止错误地执行两次操作。检查需要从应用程序端到端地进行。例如，确保一个操作是幂等的可以通过给它分配一个唯一的标识符来完成，并检查该操作对于该 id 只执行一次。有时，在出现问题时能够做出补偿也比花大力气去预防更好。例如，如果账户已经透支，则进行补偿交易，或者如果航班已经超额预订，则进行道歉和补偿。如果不是经常发生，对于大多数商家来说是可以接受的。通过异步检查约束，您可以避免大部分的协调，并且仍然保持完整性，同时性能也很好。

与数据流相关的是从请求/响应系统转移到发布/订阅数据流的讨论。如果您得到所有更改的通知，您可以保持视图最新(与电子表格的工作方式相比，电子表格的更改会在单元格中蔓延)。然而很难做到这一点，因为请求/响应的假设在数据库、库和框架中根深蒂固。

本章的最后一节讨论了开发数据处理系统时的伦理考虑。一个有趣的思想实验是用监视代替数据这个词。“在我们监控驱动的组织中，我们收集实时监控流，并将其存储在我们的监控仓库中。我们的监控科学家使用高级分析和监控处理来获得新的见解。”

### [](#nuggets)掘金

整本书中有很多我觉得非常有趣的信息。以下是我最喜欢的几个。

*   内存数据库并不比基于磁盘存储的数据库快，因为它们可以从内存中读取，而传统的数据库从磁盘中读取。操作系统会将最近使用过的磁盘块缓存在内存中。相反，速度优势来自于不必将内存中的数据结构编码成适合写入磁盘的格式(第 89 页)。
*   某些语言的内置哈希函数不适合获取分区键，因为同一个键在不同的进程中可能有不同的哈希值。比如 Java 里的 *Object.hashCode()* 和 Ruby 里的 *Object#hash* (第 203 页)。
*   在谷歌，运行一个小时的 MapReduce 任务有 5%的风险被终止。这一比率比硬件问题、机器重启等导致的故障率高出一个数量级以上。MapReduce 被设计为能够容忍频繁的意外任务终止的原因不是因为硬件特别不可靠，而是因为任意终止进程的自由使得计算集群中的资源利用率更高(418 页)。

每一章都以引用开始。其中有两个我特别喜欢。第一个，来自第 5 章，是我一直以来最喜欢的关于软件开发的名言之一:

一个有效的复杂系统总是被发现是从一个有效的简单系统进化而来的。反命题似乎也是正确的:从零开始设计的复杂系统永远不会起作用，也不可能让它起作用。约翰·高尔，《T2 系统动作》(1975 年)

这是第二段引文，来自第 11 章:

一件可能出错的事情和一件不可能出错的事情之间的主要区别在于，当一件不可能出错的事情出错时，它通常被证明是不可能得到或修复的。——道格拉斯·亚当斯，*大多无害* (1992)

### [](#conclusion)结论

如今，感觉大多数系统在某种程度上都是分布式系统。设计数据密集型应用程序几乎应该是所有软件开发人员的必读之作。里面解释的这么多概念，知道了真的很有用。

书中描述和解决的许多问题都可以归结为并发性问题。通常，有很好的图片和图表来说明这些观点。在每一章的开始有一个幻想风格的地图，列出了下一章的关键概念。我很喜欢那些。

设计数据密集型应用程序很厚——超过 550 页。这让我犹豫要不要启动它——感觉太壮观了。幸运的是，我们为今年春天工作的[书友会](https://henrikwarne.com/2016/11/08/developer-book-club/)挑选了它。这给了我足够的动力去开始并坚持下去。我真的很高兴我开始了，因为有这么多好的信息在里面。我特别喜欢它同时兼具理论性和实用性。

如果你喜欢这个总结，你绝对应该读完整本书。还有很多细节和例子，都很有趣。强烈推荐！**