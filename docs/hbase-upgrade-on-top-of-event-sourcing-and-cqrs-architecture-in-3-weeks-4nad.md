# 活动采购和 CQRS 架构的 HBase 升级在 3 周内完成

> 原文：<https://dev.to/seikoudoku2000/hbase-upgrade-on-top-of-event-sourcing-and-cqrs-architecture-in-3-weeks-4nad>

由于原始帖子中的降价方言，交叉帖子中存在一些问题。特别是原帖中的图没有显示出来。所以如果你感兴趣的话，也请检查一下原始版本。我觉得原版的更好理解

[在 3 周内完成活动采购和 CQRS 架构的 HBase 升级](https://creators-note.chatwork.com/entry/carbon-x-en)

# TL；速度三角形定位法(dead reckoning)

*   在事件采购和 CQRS 架构系统之上，我们对 HBase 版本升级采用了蓝绿色部署策略。
*   这种部署方法非常有效，总共只用了 3 周时间就完成了项目目标。这次经历对我们来说既新鲜又令人兴奋。所以想分享一下:)

# 关于数据库升级

数据库升级总是很麻烦，每当你在生产场景中处理这种情况时，你都会超级紧张*(我可以说是你正在处理的其他生产操作的 100 倍)*。

这种感觉很难与没有操作数据库环境的经验或知识的人分享。我认为 99.9%的人会同意，如果你有经验，经历过处理数据库相关操作的困难时期。风险很大，成本也很高，但升级本身并不意味着它为产品提供了新的价值，尽管在许多情况下，除非有紧急原因，否则它不会被优先考虑。

与此同时，如果数据库变得“不可触及”,这是一个巨大的隐藏风险，如何处理这个问题一直是一个话题，许多开发人员和运营商一直在与这种情况作斗争

# 升级方式

一般来说，你有两种选择。

## 滚动升级

一种是滚动升级。按顺序逐个升级数据库版本。我在这里找到了一个很好的解释。如果你不熟悉这个词，请读一下。

软件开发中的滚动升级是什么意思？

*   赞成的意见

    *   数据在一个地方。因此，您不需要考虑如何在不同的集群之间同步数据，以及如何保证同步完美运行。
*   骗局

    *   一旦升级完成，就没有简单的恢复方法。因此，如果升级以某种方式触发了性能问题，您就有大麻烦了。
    *   长期运行的数据库有一些无法在测试环境中重现的意外状态。有时候你需要处理生产中的问题。这种可能性让你非常紧张。

## 蓝绿调配

另一种是蓝绿部署。在这种情况下，您必须单独提供升级的数据库集群，并在某个时候切换应用程序以使用新的集群。如果你不熟悉“蓝绿部署”这个词，请看看这篇博文。

[蓝绿色部署](https://martinfowler.com/bliki/BlueGreenDeployment.html)

我认为这种方法在 web 应用部署中很普遍，但是如果你把“路由器”这个词换成“应用”，把“web 服务器”换成“数据库”，同样的方法也可以应用到数据库升级中。

*   赞成的意见

    *   升级时，您不会碰到正在运行的生产数据库。与滚动升级方法相比，这使您的生活更加轻松。
    *   当发生一些意外问题时，您可以很容易地恢复到旧集群。您还可以逐步分发请求，以便在遇到问题时可以最小化范围(要做到这一点，就像在“Cons”中一样，您需要将数据从新集群同步到旧集群)
    *   由于上述因素，您可以在某种程度上缩短测试环境中的负载测试，并且可以快速地进行项目。
*   骗局

    *   您需要确保两个数据库集群之间的数据同步。不仅从旧集群到新集群，而且从新集群到旧集群，如果您希望在升级后有一种简单的恢复方式。但是在许多情况下，相互的数据复制是相当困难的。每次操作都可以写入两个群集，但是您需要做好准备，以防只有一个群集关闭，并且对该群集的操作失败。处理起来会非常复杂。
    *   运行两个集群时，您需要两倍大小的服务器。如果你的系统不在云基础设施上，这将会花费一些钱，而且会很困难。

# 我们的方法

基本上，我们的方法是蓝绿部署。因为我们前面有 Kafka 作为事件源总线，所以处理上面列出的“缺点”中的数据同步问题要容易得多。

## 当前架构

首先，我来介绍一下基本架构。Btw，我们把整个聊天消息子系统叫做“猎鹰”。这就是为什么图中有猎鹰图标。

1.  当最终用户发布聊天消息时，write-api 将消息数据放入 Kafka
2.  read-model-updater(简称“rmu”)从 Kafka 获取数据，将其转换为 read-model 并放入 HBase
3.  当最终用户阅读聊天消息时，read-api 从 HBase 中提取消息数据

在这篇文章中，我没有解释我们为什么选择 CQRS。所以，如果你想知道细节或者你不熟悉 CQRS 的概念，请查看下面的幻灯片。
[Kafka Summit SF 2017-Kafka 和 Kafka Streams 的全球可扩展和弹性消息服务](https://www.slideshare.net/ConfluentInc/worldwide-scalable-and-resilient-messaging-services-with-kafka-and-kafka-streams)
[CQRS 的全球可扩展和弹性消息服务以及使用 Akka、Kafka Streams 和 HBase 的事件源](https://www.slideshare.net/Hadoop_Summit/worldwide-scalable-and-resilient-messaging-services-by-cqrs-and-event-sourcing-using-akka-kafka-streams-and-hbase)

## 数据库升级流程

现在，我将解释我们如何在此体系结构的基础上进行数据库升级

**步骤 1:** 准备新的集群并从备份进行初始恢复。

**步骤 2:** 准备另一个消费者(本图中的 rmu2)将数据从 Kafka 同步到新的数据库集群。您将从初始恢复之前开始重新播放旧的 Kafka 事件。确保在您的消费者身上实现幂等性。我的意思是，即使同一个事件被消费了不止一次，系统也需要正常工作。

**第三步:**当新消费者(rmu2)获得最新的 Kafka 消息时，准备另一个 read-api 从新的数据库集群中提取数据。并逐渐向新的 read-api 发送请求。

即使数据同步在几毫秒内完成，旧集群和新集群之间也会有一些状态差异。由于这种差异，我们遇到了一个小问题，因此您需要事先确认并运行评估检查，以了解通过集群和您的应用程序逻辑之间的差异会引发什么样的问题。或者，如果在 read-api 之前有一些好的层来根据用户属性或其他东西(例如，通过 Nginx 或 proxy 之类的代理进行路由)分发请求，您可以在那里设置适当的规则，差异可以得到有效处理，这不会成为问题。

在这个项目的回顾中，我们注意到，如果您可以将请求从现有的 api 镜像到新的 api，您就可以使用生产流量进行负载测试，而不会影响最终用户。

**第四步:**当你确定一切正常时，100%切换到新的 read-api，关闭旧的集群和应用程序。

## 为什么我认为这种方法更好

我来解释一下和正常蓝绿做法的区别。普通 blue-green 的一个问题是，您需要确保两个集群上的数据同步，理想情况下不仅是在升级之前，而且在升级之后。在这种方法中，不是使用数据库提供的复制功能，而是通过我们编写和准备的应用程序单独应用数据库更新。这种方法给我们带来很多好处。

首先，因为它们是分开工作的，你不需要关心数据在每个阶段是如何同步的。特别是，如果您希望在升级后有一种简单的恢复方式，您需要额外的(在大多数情况下相当困难的)工作来将新集群的数据同步到旧集群。但是在这种方法中，他们只是独立工作。所以你可以恢复使用旧的，以防升级后出现一些意想不到的问题。

其次，你不需要为旧集群和新集群之间的版本兼容性而烦恼。如果使用数据库提供的集群数据同步功能，在某些边缘情况下可能会出现一些版本限制和兼容性问题。但是在这种方法中，您所需要做的就是准备将数据放入每个数据库的独立应用程序。我认为在大多数情况下，这是一个你可以更容易解决的问题。从理论上讲，不仅可以更新数据库版本，还可以使用相同的方法将新集群切换到一个完全不同的集群(例如 DynamoDB)。在这种情况下，您不能使用备份数据进行初始设置，需要准备初始数据迁移程序。那要花一些时间，但我认为这是可以处理的合理项目。

# 结论

CQRS 和事件源主题经常在软件架构中被讨论。从操作的角度来看，多一层作为事件总线会增加基础设施的复杂性和操作成本。老实说，我以前并不太喜欢这种方式。但我们注意到，它也改变了我们操作基础设施的方式，给我们带来了数据库操作的平静。是的，我现在非常喜欢 CQRS 和活动采购:)

# 下一次挑战

你可能想知道我们会升级 Kafka(事件源总线)什么？是的，那将是我们的下一个挑战。我希望有比正常的滚动升级和蓝绿部署更好的方法。工程师生活还在继续！