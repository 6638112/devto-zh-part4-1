# 使用逻辑时钟的分布式互斥

> 原文:[https://dev . to/renegade coder 94/distributed-mutual-exclusive-using-logical-clocks-4927](https://dev.to/renegadecoder94/distributed-mutual-exclusion-using-logical-clocks-4927)

随着进程同步的消失，是时候研究分布式系统同步了——特别是使用逻辑时钟的分布式互斥。再一次，这篇文章的目的是为了在我的博士资格考试之前进一步巩固我对这个概念的理解。

## [](#distributed-mutual-exclusion-overview)分布式互斥概述

到目前为止，互斥是我们能够在同一台机器上的进程之间完成的事情。换句话说，这些进程共享相同的硬件和操作系统，所以我们只需要担心如何在那个环境中导航。

现在，我们对分布式系统感兴趣。换句话说，一个拥有自己环境的机器网络。例如，互联网是一个巨大的分布式系统。当然，我们可以在家里拥有比局域网(LAN)更小的分布式系统。

有时，这些网络上的进程需要共享数据，就像同一台机器上的进程一样。很自然，问题变成了:“我们如何保护那些关键部分？”在本文中，我们将把逻辑时钟视为同步分布式系统的一种机制

同样，本文的材料是从俄亥俄州立大学 CSE 6431 课程的课堂笔记中借来的。请随意浏览下面的幻灯片:

*   [OSU CSE 6431 分布式互斥第一部分](https://therenegadecoder.com/wp-content/uploads/2019/07/osu-cse-6431-distributed-mutual-exclusion-part-1.pdf?x24663)(逻辑时钟)
*   [OSU CSE 6431 分布式互斥第二部分](https://therenegadecoder.com/wp-content/uploads/2019/07/osu-cse-6431-distributed-mutual-exclusion-part-2.pdf?x24663)(向量时钟)
*   [OSU CSE 6431 分布式互斥第三部分](https://therenegadecoder.com/wp-content/uploads/2019/07/osu-cse-6431-distributed-mutual-exclusion-part-3.pdf?x24663) (Lamport & Ricart-Agrawala 算法)
*   [OSU CSE 6431 分布式互斥第四部分](https://therenegadecoder.com/wp-content/uploads/2019/07/osu-cse-6431-distributed-mutual-exclusion-part-4.pdf?x24663)(前川算法)

一如既往，所有的写作都是我自己的。

## [](#introduction-to-logical-clocks)逻辑时钟简介

同步分布式系统的一种方法是在该系统上强加一个时钟，就像我们今天处理处理器的方式一样。当然，事情从来没有这么简单。

### [](#global-clocks)全局时钟

通常，当我们想和某人分享信息时，我们会受到我们和那个人之间的距离的限制。例如，如果这个人离我们很近，我们也许可以直接和他们交流。然而，如果他们离得更远，我们可能会选择打电话，甚至发短信。如果他们在某个遥远的地方，我们甚至可以决定寄一封信。

不幸的是，传递一条信息所花费的时间是可以忽略不计的。例如，在最后一种情况下，其他人可能需要几天才能收到我们的信息。此外，他们需要时间来写回复，甚至需要更多时间来回复。

如果由于某种原因，我们不得不发送时间敏感的信息(例如，我们 3 号在镇上见面)，他们可能不会及时收到我们的信。即使他们及时收到了信，我们也可能无法及时收到他们的回复(即他们不能按时到达)。

当然，一个解决方案是制定长远的未来计划，这样就不会有任何一条信息不能及时传达的风险。可悲的是，仍然存在潜在的问题。例如，有些事情可能会阻止我们的朋友做出承诺，而他们可能不会发现，直到提醒我们时已经太晚了。幸运的是，我们并不真的需要处理这类问题，但是它们仍然存在于分布式系统中。

我刚刚描述的类似于分布式系统如何与全局时钟一起工作。换句话说，进程会在假设所有进程都知道当前时间的基础上做出决策。当然，这个假设不可能是真的，因为消息有不可预测的延迟。因此，一个进程可能会因为其本地时钟太快或太慢而损坏共享内存。

### [](#the-happensbefore-relation)发生之前的关系

我们可以开始将机器之间的交互视为事件，而不是处理时间戳。例如，看看下面的伪代码:

```
x = 10
x = x + 1
y = x - 2 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

在这个例子中，我们有两个共享内存变量(x 和 y ),它们以某种顺序相互作用:

1.  写 10 到 x
2.  阅读 x
3.  写 11 到 x
4.  阅读 x
5.  写 9 到 y

在这个例子中，我们不关心这些事件发生的实际时间。我们只关心他们的顺序，因为他们的顺序决定了结果。特别是，交换行可以给共享变量显著不同的值。更具体地说，写入 x 必须“发生在”我们可以读取它以增加它之前。

在分布式系统中，我们可以将这种先发生的想法提升到一个新的水平。特别是，当两个进程交换消息时，一个进程必须在另一个进程能够接收到消息之前发送消息。因此，我们可以开始推理分布式系统中事件的逻辑顺序。

更进一步说，发生之前的关系是可传递的。如果某个事件`a`发生在某个其他事件`b`之前，并且`b`发生在某个第三事件`c`之前，那么`a`必须发生在`c`之前。记住这个属性，我们就可以开始同步事件了。

### [](#lamports-logical-clock)Lamport 的逻辑时钟

有趣的是，发生之前的关系实现起来非常简单。我们所要做的就是让每个进程( *P* <sub>*i*</sub> )使用以下规则跟踪它们自己的带有时间戳的事件:

*   在*P*<sub>*I*</sub>(*d*>0)的每个事件中，时钟*C*<sub>T3】IT5】增加 *d*</sub>
*   当 *P*
*   当 *P* <sub>*i*</sub> 收到消息 *m* ， *P* <sub>*i*</sub> 将其时钟设置为其时间的最大值，消息上的时间戳加上*d*(*C*<sub>*I*</sub>= max(*C*<sub>*I*</sub>

换句话说，进程维护它们自己的时钟，并且只有当它们接收到具有更高时间戳的消息时才更新它们。下面是该算法的一个应用示例:

[![Lamport's Logical Clocks](../Images/7bc753015f8b9404ffb65209ed3a63ac.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--690UIijl--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i0.wp.com/therenegadecoder.com/wp-content/uploads/2019/07/lamport-s-logical-clocks.png%3Fresize%3D800%252C534%26ssl%3D1)

在这个例子中，我们有两个进程: *P* <sub>*1*</sub> 和 *P* <sub>*2*</sub> 。每个过程都用一条向右无限延伸的线来表示。在每一行上，我们会注意到几个橙色的点。这些点表示事件，我们根据 Lamport 的逻辑时钟算法用时间戳标记每个事件。

偶尔，我们会注意到进程之间有一个箭头。这些箭头表示进程之间传递的消息。根据我们的算法，消息发送者将他们的当前时间戳附加到他们的消息上，因此消息接收者可以在必要时更新他们的本地时钟。看看您是否注意到了某个进程需要更新时钟的地方。

### [](#vector-clocks)矢量时钟

现在，Lamport 的逻辑时钟有一点限制，因为发生之前的关系只意味着一个进程的时间戳比另一个进程的时间戳小。不幸的是，仅仅知道时间戳不足以证明之前发生的关系。为此，我们必须引入矢量时钟。

像 Lamport 的逻辑时钟一样，矢量时钟也是利用发生之前的关系工作的。然而，矢量时钟不是跟踪单个本地时钟，而是跟踪所有进程的所有时钟。当然，我们不想引入全局时钟，所以每个进程维护自己的时钟以及对所有其他时钟的最佳猜测。特别是，矢量时钟使用以下规则:

*   时钟*C*<sub>T3】IT5】是一个长度为 *n* 的向量其中*C*<sub>*I*</sub>【I】是它自己的逻辑时钟</sub>
*   当事件 *a* 和 *b* 在同一个进程上时，将该进程的时钟增加*d*(*C*<sub>*I*</sub>【I】=*C*<sub>*I*</sub>【I】+*d*
*   当 *P*

自然，定义可能很难理解，所以让我们看一下从幻灯片中借用的另一个示例:

[![Vector Clocks](../Images/b3532cc1c2aa0f4c3288bf6b2679f23b.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--khSobJTf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i2.wp.com/therenegadecoder.com/wp-content/uploads/2019/07/vector-clocks.png%3Ffit%3D800%252C534%26ssl%3D1)

与逻辑时钟相比，使用矢量时钟的主要优势在于，我们可以开始研究因果关系。特别地，如果一个矢量时钟事件(E1)的所有时间戳小于另一个矢量时钟事件(E2)的所有时间戳，我们可以假设第一个事件(E1)在第二个事件(E2)之前发生。

## [](#mutual-exclusion-using-logical-clocks)互斥使用逻辑时钟

有了逻辑时钟的概念，我们可以开始寻找在分布式系统中应用互斥的更好方法。具体来说，我们将从高层次来看三种算法:Lamport、Ricart-Agrawala 和 Maekawa。

在我们开始之前，我想提一下，这里有一种显而易见的方法来提供互斥，对吗？与其让一些复杂的异步进程来处理临界区问题，我们可以提供一些集中的站点，向想要进入其临界区的进程授予许可。在接下来的部分中，我们将看看为什么这可能不是最好的做法。

### [](#lamport-algorithm)Lamport 算法

与其提供一个集中的站点，不如我们开发一些消息传递方案，这样所有的进程最终都会同意轮流访问它们的关键部分。这正是 Lamport 算法的工作原理。

Lamport 算法通过传递三个消息来工作:请求、回复和释放。当一个进程想要请求访问它们的临界区时，它们向所有其他进程发送一个请求消息，然后将该请求放入自己的队列中。每个接收请求消息的进程在将请求排入自己的队列之前都会返回一条回复消息。

从它们的，一个请求进程只有当它从所有其他进程收到时间戳大于其当前时间的回复时，才进入它的临界区，并且它在它的队列中是第一个。

在处理完它的临界区之后，进程从它的队列中删除它的请求，并向所有其他进程发送一个释放消息。当接收到释放消息时，每个进程将从其队列中移除释放进程的请求。

和往常一样，看一张图片要容易得多，所以下面是实际使用的算法:

[![Lamport Algorithm](../Images/859835d1d4f25452dd6c056eb92ed301.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--d5Sca0RK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i2.wp.com/therenegadecoder.com/wp-content/uploads/2019/07/lamport-algorithm.png%3Ffit%3D800%252C534%26ssl%3D1)

每一步都显示了算法所经历的阶段。例如，步骤 1 显示了为流程 1 和流程 2 发出的请求消息。然后，在步骤 2 中，发送回复。在这一点上，进程二进入其关键部分。最后，在步骤 3 中，流程二发送一对释放消息，因此流程一可以开始执行。

遗憾的是，Lamport 算法的主要问题是它依赖先进先出(FIFO)通信。换句话说，进程间传输延迟的差异会导致互斥的破坏。

例如，假设我们有一个双进程分布式系统。如果一个队列为空的进程发送一个请求并收到一个响应，会发生什么？它应该开始执行，对吗？事实证明，发送回复的进程可能碰巧在更早的时候发送了一个请求。然而，不知何故，回复胜过了对另一个进程的请求。结果，两个进程都可能在它们的临界区结束。

### [](#ricartagrawala-algorithm)李嘉图-阿格拉瓦拉算法

不幸的是，Lamport 算法有几个缺点。首先，它假设 FIFO 是不现实的。此外，还有许多不必要的消息传递，算法依赖于队列。幸运的是，Ricart-Agrawala 算法对之前的算法做了一些小的改进。

与 Lamport 算法一样，Ricart-Agrawala 算法利用消息传递和逻辑时钟来实现互斥。然而，Ricart-Agrawala 算法只使用了两条消息:请求和回复，而不是三条消息。

每当一个进程需要访问它的临界区时，它向所有其他进程发送一个请求消息——不需要队列。如果每个收到请求消息的进程没有执行它的临界区，或者如果它的请求有一个更大的时间戳，它就会发送一个回复消息。否则，它将推迟回复。

最终，一个进程只有在收到所有进程的回复后才能访问它的临界区。在访问其临界区之后，该进程向所有被推迟的进程发送一个回复消息。

和往常一样，看一个例子来真正理解这个算法是很有帮助的:

[![Ricart-Agrawala Algorithm](../Images/5848afd259d7c4b29d355ddbcd366219.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--nLVFevk3--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i2.wp.com/therenegadecoder.com/wp-content/uploads/2019/07/ricart-agrawala-algorithm.png%3Ffit%3D800%252C534%26ssl%3D1)

正如我们所看到的，这里的消息比 Lamport 算法少一些。特别是，我们可以压缩前面算法的第一步和第二步，并在此过程中删除一些消息。此外，我们必须维护的唯一队列是延迟队列。

在步骤 1 中，进程二获取临界区。然后，在第二步中，在完成消息的关键部分后，处理两条消息(延迟处理的消息)。此时，流程一进入其关键部分。

由于这种算法的性质，没有 FIFO 的限制。这是因为每个进程都要亲自负责授予权限。即使由于传输延迟而出现无序消息，由于逻辑时钟，回复消息也不会到来。

### [](#maekawa-algorithm)前川算法

通常，当一个进程想要访问它的临界区时，它会将请求发送给分布式系统中的其他进程。当然，等待每个进程回复需要时间，因此减少进程必须发送的消息总数可以大大提高性能。

与 Lamport 和 Ricart-Agrawala 算法不同，Maekawa 算法引入了请求集，这些请求集是具有一些特殊属性的进程组。特别地，每对请求集共享至少一个进程。

每当一个进程想要访问它的临界区时，它就向其请求集中的所有进程发送一个请求消息。当流程接收到请求消息时，如果自上次接收到释放消息以来没有发送回复消息，它将发送回复消息。否则，流程会将请求消息存储在队列中。

自然地，一旦一个进程从它的请求集中收到所有的回复，它就能够访问它的临界区。当进程完成执行时，它向其请求集中的所有进程发送一个释放消息。一个进程一收到释放消息，它就向队列中等待的下一个进程发送回复消息。

虽然算法本身非常简单，但实际上有很多规则围绕着设置请求集。例如，我们已经提到，每两个集合应该至少有一个重叠的过程。此外，最好确保所有请求集的大小相同，并且每个进程在所有请求集中出现的次数相同。换句话说，请求集应该有一个固定的大小(K ),而进程应该只存在于固定数量的请求集中(也是 K)。

显然，使用下面的等式可以满足上述条件:

```
 N = K(K - 1) + 1 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

在这个等式中，N 是进程的数量，K 是每个请求站点的大小。例如，N = 7 和 K = 3 是有效的结构，可能如下所示:

[![Maekawa Request Sets](../Images/ad336546c4df657dacbc25a8cfb7ab13.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--XxLjkljE--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i1.wp.com/therenegadecoder.com/wp-content/uploads/2019/07/maekawa-request-sets.png%3Ffit%3D800%252C534%26ssl%3D1)

尽管如此，这个算法有一个主要的警告:它容易死锁。毕竟，由于成对的站点会处理冲突，所以少数请求站点之间可能会出现冲突循环。

## [](#want-to-learn-more)想了解更多？

到目前为止，我们已经讨论了大部分操作系统主题，并且我们仅仅进行了一半。在此之后，大约还有三个主题需要讨论:数据库并发控制、死锁和容错。

就时间表而言，完成操作系统会让我一直坚持到考试前两周。之后，我将开始钻研其他两门课程。显然，这些文章中的大部分在我参加考试之前不会发表，但我认为它们仍然会给我提供很多价值。

无论如何，如果你想在这个旅程中支持我，请确保[成为会员](https://www.patreon.com/TheRenegadeCoder)。如果你手头拮据，你可以随时[加入邮件列表](https://newsletter.therenegadecoder.com/)，那里你会在每周五收到更新。

既然你在这里，为什么不看看下面的一些文章呢？

*   [读者-作者问题的解决方案](https://dev.to/renegadecoder94/solutions-to-the-readers-writers-problem-1147)
*   [了解 RSA 加密背后的数论](https://dev.to/renegadecoder94/understanding-the-number-theory-behind-rsa-encryption-1pdo)
*   [语句和表达式的区别](https://dev.to/renegadecoder94/the-difference-between-statements-and-expressions-1e47)

再次感谢您的支持！

帖子[使用逻辑时钟](https://therenegadecoder.com/code/distributed-mutual-exclusion-using-logical-clocks/)的分布式互斥最早出现在[叛徒编码](https://therenegadecoder.com)上。