# 在编写下一个处理管道时考虑 SQL

> 原文:[https://dev . to/data form/consider-SQL-when-writing-your-next-processing-pipeline-1 ojg](https://dev.to/dataform/consider-sql-when-writing-your-next-processing-pipeline-1ojg)

一旦一个团队或组织需要管理一些数据——客户数据、要输入到某个机器学习系统的事件，或者其他任何东西——他们几乎马上就会发现自己正在编写、运行和维护处理管道。

这些管道的输出是多种多样的，包括客户/市场分析、数据清理等，但这些管道似乎比人们预期的更频繁、更迅速地出现。

如今，大多数重要的数据处理都是使用某种流水线技术完成的，例如数据流/ Apache Beam，用户代码通常用 Java、Python 或 Go 等语言编写。

#### [](#my-experience)我的经历

我在 Google 做了几年的软件工程师，在此期间，我领导了多个团队和项目，这些团队和项目需要编写、管理和维护各种类型的处理管道。在那段时间里，我开始相信——对于大多数用例来说——**用 SQL 表达这些管道比其他方法更简单、更便宜、更容易，几乎没有缺点**。

值得一提的是，我会注意到我实际上是这些流水线技术的忠实粉丝。在谷歌的时候，我是云数据流(Flume)内部版本的支持者，支持批处理和流用例。然而，我认为使用它们的理由——广泛地说——不再适用于当今高度可扩展的云仓库和查询引擎的世界。

### [](#why-isnt-sql-the-de-facto-processing-pipeline-language-today)为什么 SQL 不是今天事实上的处理流水线语言？

在我们拥有广泛可用的云数据仓库(如 BigQuery 和 Redshift)之前，SQL 并不是一个真正可扩展的数据处理选项。如果没有这些高度可伸缩的查询引擎，唯一合理的选择就是在数据仓库之外执行任何重要的数据处理。

#### [](#scalable-processing)可扩展处理

第一个真正可扩展的数据处理解决方案可能是类似 Google MapReduce 的东西。然后很快就变得很明显，使用一些高级 API 将类似 MapReduce 的处理步骤链接成完整的管道可以产生非常强大的管道系统，Hadoop、Apache Spark 和 Google Cloud Dataflow 等框架就这样诞生了。这些系统使用户能够快速、可扩展地处理万亿字节(或更多，经过一些调整)的数据，这在使用 SQL 查询引擎时通常是不可能的。

然而，云数据仓库系统在过去 5 年里发生了巨大的变化。在 BigQuery 的查询引擎上运行的 SQL 查询通常会比其他方法运行得更快，后者需要从仓库中读取所有相关数据，对其进行处理，然后将结果写回到其他表中。在生产中运行也容易得多；不需要管理临时状态，查询会自动优化，等等。所有这些问题都推给了查询引擎，用户不必关心它们。

查询引擎是优化管道的最佳位置，因为它可以访问关于正在处理的数据的大多数元数据；因此，在生产中更容易操作性地管理管道。这比其他选择好得多——我无法告诉你我和我的团队花了多少时间(或几天，甚至几周)来调试 Java 管道中的可伸缩性问题和糟糕的优化选择。

#### [](#existing-bias-towards-imperative-languages)对命令式语言的现存偏见

我认为在软件工程团队中有一种可以理解的文化偏见，倾向于使用标准的命令式编程语言来实现处理管道，直到最近才真正有可能混合和匹配 SQL 和非 SQL(参见下面的更多内容)。

工程师们更熟悉在生产中配置用这些语言编写的作业，但令人高兴的是，现代 SaaS 选项通过负责调度和运行用户代码为 SQL 管道避免了这个问题，因此**用户根本不需要做什么生产化**。

此外，与其他语言相比，SQL 脚本有时被视为二等公民。一些用于 SQL 脚本开发的工具不支持标准的软件工程技术，如版本控制或代码审查。然而，这也发生了变化，现代工具链选项将这些实践作为一流的功能来支持。

### [](#sql-has-distinct-advantages-over-the-alternatives)SQL 比其他替代产品有明显的优势

SQL 是一种专门为支持您在处理数据时想要做的事情而构建和设计的语言:连接、过滤、聚合和转换数据。因此，用 SQL 来表达你的管道通常比用其他管道技术要简单和容易得多。(如果你想看看 SQL 有多强大的例子，看看[这篇文章](https://towardsdatascience.com/deep-neural-network-implemented-in-pure-sql-over-bigquery-f3ed245814d3)，其中用它实现了一个深度神经网络！)

#### [](#a-common-language)共同语言

在 SQL 中实现管道的最大优点是，它很可能是您或您的数据团队用来对管道的输出进行最终分析的同一种语言。

这意味着数据团队不需要工程师的支持来改变管道。相反，他们有权自己做出改变。

#### [](#debugging)调试

当出现问题时，SQL 管道通常比备选方案更容易自省。如果您想要检查 SQL 管道的任何给定处理阶段到底输出了什么数据，您可以简单地将这些结果提取到一些相关的 SELECT 查询中。

使用流水线系统做同样的事情可能是一件非常痛苦的事情，包括进行重大的代码修改(只是为了添加足够的工具来进行调试)和重新部署流水线。

#### [](#faster-development)发展更快

在基于 SQL 的管道开发过程中，迭代周期明显加快。这是因为反馈循环要快得多——对您的查询进行编辑，重新运行管道，并立即获得新的结果。

如果管道处理的数据太多，以至于执行时间超过一两分钟，那么通过向查询(或子查询)添加限制，或者通过只选择属于输入数据集子集的行来处理一小部分数据(以更快地获得结果)是微不足道的。

当从头开始编写 Java 管道时，我经常会发现测试一个 bug 修复需要几个小时——而 SQL 则不然。实际上，我经常发现自己在编写一个 SQL 脚本来验证一些生产化的 Java 管道的输出，结果才姗姗来迟地意识到我实际上是用 SQL 重新实现了 Java 管道——用了更少的代码行，可读性更好，复杂性也大大降低了。

### [](#sqls-disadvantages)SQL 的缺点

根据我的经验，其他语言在两个不同的领域比纯 SQL 有优势:(1)单元测试和(2)特别复杂的数据转换的可读性。

一些 SQL 查询可能相当复杂，尤其是当它们使用强大的功能时，比如 BigQuery 的[分析函数](https://cloud.google.com/bigquery/docs/reference/standard-sql/analytic-function-concepts)。我希望能够为这些 SQL 查询编写单元测试，静态地定义输入行和预期输出行的集合，断言查询确实做了它应该做的事情。我们正致力于在 Dataform 中实现这一特性，并期望很快提供基本的单元测试支持。然而，一个有用的工具是[数据断言](https://dataform.co/blog/data-assertions/?utm_medium=organic&utm_source=dev_to&utm_campaign=consider_sql)，使用它你可以表达你的输入数据的需求，例如在继续运行你的处理管道之前检查正确性。

有时，您会想要运行一些特别复杂的数据转换逻辑。(举一个有趣的例子——如果有点疯狂的话——看看[这篇](https://medium.com/@urish/yes-i-compiled-1-000-000-typescript-files-in-under-40-seconds-this-is-how-6429a665999c)中型文章。)有时，当用 SQL 表达时，由于其复杂性，这可能变得难以阅读和/或维护。然而，这个问题有一个很好的解决方案:用户定义函数(UDF)。当您需要完整的命令式编程语言来实现自己的功能时，UDF 允许您脱离 SQL，使用 JavaScript 或 Python(取决于仓库)。

### [](#the-future)未来

我们看到了用普通 SQL 表达管道的普遍趋势。事实上，Apache Beam 最近推出了对 Beam SQL 的[支持](https://beam.apache.org/documentation/dsls/sql/overview/)，允许 Java 用户使用内联 SQL 来表达转换。我希望随着时间的推移，我们会看到越来越少的处理管道使用 Java/Python/Go 来表达，而更多的工作在数据仓库中使用简单的 SQL 来完成，原因如上所述。