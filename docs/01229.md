# 为什么我们选择 Apache Spark 进行 ETL(提取-转换-加载)

> 原文：<https://dev.to/sumitkumar1209/why-we-chose-apache-spark-for-etl-extract-transform-load-58op>

[![](img/d3b259a291e043b3ddf10e60d1afcd77.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--1YVBc2S2--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/1024/1%2AG7_FggWo15o5qVbF4COeUA.png) 

<figcaption>信用:</figcaption>

甚至在我加入 Postman 之前，我的同事们已经在处理全球 600 万用户的规模。需要处理的数据量是巨大的，以获得一些有意义的见解。以下是它的规模:

1.  每天超过 1 亿个请求分布在 30 多个微服务中
2.  存放大约 10 TB 的数据
3.  每月吸收大约 1TB 的内部服务日志
4.  100k+峰值并发 web 套接字连接

### 背故事:

我在邮递员岗位上干了几个月。我被分配到一个需要处理数百万行服务日志的项目中。这些跨度超过千兆字节的数据。

毫无疑问，我们可以用普通代码处理这些日志，也许还可以使用一些库。但是这将导致操作和维护代码库的更多成本。此外，没有经过严格测试的库增加了 bug 的表面积。所有这些增加的库和基础结构导致了工时的增加。然后我们决定找点别的。

### 想法:

由于以前在分布式系统方面的经验，我和我的团队知道它的优势和局限性。记住这一点，我们的下一步是寻找分布式处理的解决方案。别忘了地图缩小功能。

波兹曼信奉一种哲学，即人的时间是最宝贵的资源。我们总是尽可能争取一个可管理的解决方案。维护解决方案自行处理软件和硬件的升级(第三方)。我们只需要关注逻辑，而不是它周围的任何东西。

> 我们参加了 2018 年 [AWS 社区日，Bengaluru](http://bit.ly/2TLcJXz) 。如果你想看照片，[访问这里](http://bit.ly/2QLcSZc)。

对于外行人来说，什么是 Apache Spark？

### 辩论:

基于上述理念，我们主要希望优化以下内容:

#### 一、发展时间

那么哪种方法更快呢？

使用 Apache Spark 生态系统中可用的库，用任何编程语言

或

的普通代码开发任何项目。

普通代码的一个优点是你熟悉基本概念。你可以掌握一些技巧和诀窍，以一种让你更快发展的方式去做一些事情。这里的警告是，你能把同样的知识传播给你的团队成员吗？你可能想要更好地控制你想要达到的目标。你能确定你能把同样的知识和控制需求传递给其他开发人员吗？一个直白的问题，他们真的需要吗？

人们可以在工具生态系统中讨论类似的知识。那么，是什么让 Apache Spark 生态系统或任何其他工具生态系统比香草替代品更重要呢？

根据我的观点

1.  社区的支持，
2.  更好地记录任何方法，
3.  系统范式
4.  以及从别人的错误中学习的潜在机会的额外优势

> **附言:**有了 Apache Spark 这个开源工具，你也不会失去控制。

[![](img/5f3a0ac4b3063ee4822df85bb4da0099.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--2p_-t18h--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/517/1%2Aic7shvGnlpir0KLZlSZKkQ.jpeg)

#### 二世。模块化

在我编程的早期，我的一个同事很好地向我灌输了一个想法。我可以说这实际上改变了我写代码的方式。这个我就不花力气解释了，随便放在这里。

> “代码就像诗歌。”
> 
> *   [泰米尔塞尔万语](https://github.com/tamilmani58)

我再怎么强调模块化代码的困难也不过分。如果你不是这个项目的唯一开发者，那么也要保持不变。一个单独的开发者项目可以让你把你的想法(阅读意见)放在如何构建代码上。它可能是好的，也可能不是。当项目有多个参与者时，真正的技能测试就发生了。你的模块化应该是可消费的，不需要你向他们每一个人解释。

使用 Apache Spark 等工具，贡献的代码非常少。为什么？因为核心功能的所有细节都隐藏在库代码中。你所拥有的是一个非常简单的 ETL 过程的小衬垫。

例如，一个小而完整的 ETL 过程可以总结为

```
spark.read.parquet("/source/path) # Extract
    .filter(...).agg(...) # Transform
    .write.parquet("/destination/path") # Load 
```

Apache Spark 社区为简单的读者和作者提供了很多支持。这使您能够轻松地模块化您的代码，并坚持一种范式。那么你最终得到了什么？你得到一个漂亮的结构代码，每个人都能理解并为之做出贡献。

> **附注:**您可以随时扩展默认的阅读器和编写器，以完全满足您的需求。

[![](img/5241699fcd120a6a64245bc23ea25f16.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--5pV8_k0d--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/600/1%2AgWpLuVf43QxUKBT4B477Gw.jpeg)

#### 三世。可维护性

我坚信社区的力量。对我来说，社区可以归结为一个超级英雄联盟为一个共同的目标而战。这里引用一句话，用非常简单的话来表达我的思考过程。

> 如果两个人像一个人一样行动，两个人总比一个人好。
> 
> *   [迈克·沙舍夫斯基](https://en.wikipedia.org/wiki/Mike_Krzyzewski)

我相信这一点是因为如果一个人失败了，另一个人会帮助他。可以用这句谚语进行辩论。

> 厨师多了烧坏汤
> 
> *   谚语

也就是说如果有很多人参与做同一件事，最后的结果不会好。但是当事情发生在厨房的门后时，就会发生这种情况。

开源社区非常漂亮地解决了这个问题，证明了它的勇气。开源项目和社区的质量和数量就是证明。阿帕奇 Spark 就是其中之一。这意味着它的质量、可维护性和易用性要好得多。至少比少数厨师闭门造车打造香草产品要好。不是吧，夏洛克！

> **附言:**活跃的开源社区意味着有很多人已经在为你维护和实际工作。

#### 四世。生产时间

开发时间是一回事，在生产中实际部署代码是另一回事。大多数情况下，项目停留在“PoC”模式，并且永远不会走出这个模式。我见过一些公司在生产服务器中使用相同的“PoC”。这些“PoC”不太考虑它们是否能够处理当前的流量和负载增加的速率。

Apache Spark 等分布式系统的固有特性使得支持大规模系统变得轻而易举。这些系统设计的唯一原因就是“处理规模”。

当构建一个普通的系统时，大多数时候它被设计为处理当前的负载，假设它不会增加。在一个理想的世界里，这可能是真的，但我们并不生活在这样的世界里。

**附言:**虽然我大部分时间都在尝试[垂直缩放](https://dev.to/sumitkumar1209/optimising-e-commerce-data-2nna)，但我也做过水平缩放，这在分布式系统中非常平滑。

[![](img/5c085d9890393c09966e2941fdb7de87.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--XzeGnksp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/568/1%2AoufjjHZQVsVmCZO5AY1KEw.jpeg)

#### 诉后生产注意事项

两个世界

监控和可观察性。

我不会深入这些术语的细节，因为已经有很多相关的内容了。对于生产部署，您可能希望在一个理想的世界中“做了就忘了”，但是我们并不生活在这个世界中。在生产中部署任何东西都会带来许多或小或大的问题。生产中的系统应被持续监控，并设计成可观察的。不要忘记警报也可能在监控下减弱。Apache Spark 的 web UI 和 AWS 的支持使其成为比用普通代码构建定制解决方案更好的选择。

所以你真的想重新发明轮子吗？

**附言:**大概你没有吧。我没有评判。

### 结论:

总结我所有的废话，这里有一个**TL；为什么我们选择使用 Apache Spark 进行 ETL**

1.  AWS 支持(我们的主要需求)
2.  分布式系统(处理可伸缩性)
3.  开源(控制)
4.  社区权力(超级大国)
5.  文档(易于加入)

我通常写数据。在 medium 或[dev to](https://dev.to/sumitkumar1209)社区上找到更多来自我[的帖子。](https://medium.com/@sumitkumar1209)

* * *