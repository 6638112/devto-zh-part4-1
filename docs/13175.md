# Azure Blob 存储与 AWS S3 的无痛同步

> 原文：<https://dev.to/sheldonhull/painless-synchronization-of-azure-blob-storage-with-aws-s3-2kg2>

## 同步

在两个云提供商之间移动数据可能会很痛苦，如果进行 api 调用，需要更多的提供商脚本。为此，您可以从将调用抽象为无缝同步工具的工具中受益。

我以前在需要对我自己的 Google Drive 中的几 TB 数据进行重复数据删除时使用过 RClone，所以我想看看它是否能帮我从 Azure 向 S3 同步 25GB 的 json 文件。

我非常高兴地报告，它工作得非常完美，并且只花了几分钟的时间来重新熟悉工具设置。

## 安装 RClone

对于 windows 用户来说，这就像利用 Chocolatey 并运行
一样简单

```
choco upgrade rclone -y 
```

Enter fullscreen mode Exit fullscreen mode

## 设置提供商

通过`rclone config`对话，设置您的云提供商。在我的例子中，我将 Azure 设置为连接 blob 存储的提供者，然后用 s3 连接 AWS。

云到云

在[可选功能](http://bit.ly/2LEOSrR)部分提供了支持基于云到云的呼叫而无需本地复制的提供商，您可以在此查看支持呼叫的操作

## 初始化同步

```
rclone copy azure:containername s3:bucketname/keyprefix --log-level ERROR --progress --dry-run 
```

Enter fullscreen mode Exit fullscreen mode

## 总结

如果您需要一种简单的方法来从一个提供者获取一些数据并在另一个提供者中利用，并且您可能希望在学习特定于提供者的 api 调用上节省一些时间，请看看这个。我发现像这样的工具，Terraform 和其他帮助抽象 api 调用的工具可以是一个很好的资源，因为你可以利用一个语法与两个完全不同的提供者一起工作，并消除大量的编码工作。