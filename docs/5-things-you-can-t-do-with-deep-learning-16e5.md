# 深度学习做不到的 5 件事

> 原文：<https://dev.to/rebeccaberis/5-things-you-can-t-do-with-deep-learning-16e5>

深度学习一直是全球人们着迷的源泉。投资者和企业家正在竞相资助和发明为人工智能制造或由人工智能制造的商业和盈利产品。深度学习是机器学习的一个子领域，负责帮助机器学习。人工智能产品依靠机器学习来保持健康和改善。尽管深度学习有助于提高人工智能，但该领域并非刀枪不入。你不能用深度学习做所有的事情。

## 什么是深度学习？

深度学习是机器学习的一个子集，它使用人工神经网络来教授机器。这个概念的灵感来自人类大脑的设计，其中神经网络是学习过程发生的主要空间。在深度学习中，神经网络由硬件、软件或两者组成。

深度学习方法使用一套称为表示学习的技术来帮助教会机器基于一组样本值对数据进行分类。为此，每个神经网络包含:

*   **输入层**——由表示数据的单元组成。例如，代表图像的像素。
*   **一个或多个隐藏层** -由隐藏单元或神经元组成，
*   **输出层**——由标识输入类别的标签组成。比如猫，狗，人。##什么是深度学习神经网络？与只能去除一个隐藏层的常规神经网络不同，深度学习需要使用两个或更多隐藏层。

在图像中，每个圆圈代表一个神经元。像人脑一样，神经元的工作是传递信息。深度学习将这一过程应用于机器学习。为了帮助神经元传递信息，我们赋予神经元特定的角色:

*   **输入神经元**——接收信息。
*   **隐藏神经元**——接受输入并产生输出。
*   **输出神经元** -转发信息。

为了帮助神经元交流信息，我们在它们之间建立了连接(如图所示)。

## 深度学习用例

长期以来，深度学习一直被认为有助于提高语音识别、图像识别和翻译领域的机器学习能力。过去提供可笑翻译的谷歌翻译已经被一个帮助全世界人民的改进版本所取代。

随着我们帮助机器开发出更好、更高效的学习模式，它们的能力和专业知识也在增加。如今，世界各地的企业都在寻求开发一种面向人工智能(AI)市场的产品。由于价格合理的云计算服务，许多企业可以获得所需的资源。据 Statista 称，对人工智能产品的需求预计将继续见顶，并在 2025 年以 7.8 亿美元支撑美国深度学习服务市场。
深度学习的局限性

### 1。过度依赖数据

深度学习模型高度依赖于大量训练数据的可用性来学习抽象。这种对大量数据的依赖与人类使用有限数据学习抽象的轻松形成鲜明对比。例如，在 1999 年一项名为七个月大的婴儿学习[规则的研究中，结果表明婴儿可以使用低水平的输入信息快速抽象出类似代数的语言规则。](http://www.psych.nyu.edu/gary/marcusArticles/marcus%20et%20al%201999%20science.pdf)

鉴于人工通用智能是深度学习和其他人工智能领域许多研究的主要目标，很明显，在这方面，深度学习系统利用有限数据进行抽象的能力和人类完成这些任务的能力之间存在巨大差异。在学习抽象的训练数据有限的领域，深度学习有所欠缺。

### 2。目前的深度学习是肤浅的

深度学习模型中发生的实际学习可以说是表面的，而不是深度的。在 2015 年 Youtube 上疯传的一段视频中， [Google DeepMind](https://www.youtube.com/watch?v=V1eYniJ0Rnk) 使用一种无监督的深度学习算法来开发一种获胜策略，通过在墙上修建一条隧道来击败 Atari Breakout 游戏。虽然视频很有趣，但实际学习的程度很浅。

通过对游戏代码进行微小的修改，比如改变墙的位置，研究人员能够证明类似的 DeepMind 系统无法击败使用这种策略的游戏。有问题的深度学习模型无法对墙是什么有一个良好的、坚实的理解。

### 3。容易恶搞

计算机视觉是帮助计算机从数字图像或视频中获得高水平理解的领域，是深度学习显示出真正前景的领域。然而，在计算机视觉的[深度学习中存在严重的局限性，例如对轻微改变的物体的视觉分类。](https://missinglink.ai/)

欺骗或愚弄深度学习模型是相对简单的，正如 2018 年[的一篇论文](https://arxiv.org/pdf/1707.08945.pdf)中所指出的。这篇论文的作者通过对交通控制的实验阐明了这个问题。当他们改变停止标志的物理外观时，人工智能将它们误归类为限速标志。这种错误会造成交通堵塞或导致事故。

### 4。神经网络缺乏透明度

支撑深度学习的神经网络缺乏透明度，这使得人们很难知道这些网络如何或为什么做出决策。虽然网络可能擅长特定的任务，如对图像进行分类，但很难确定图像的哪一部分对图像的准确分类最重要。

鉴于许多关于深度学习的更耸人听闻的报告专注于金融或医疗保健用例，缺乏透明度可以被视为对负责开发或维护这些模型的人类用户的限制。如果开发人员不能调试系统，他们可能需要在业务受到严重的财务和健康影响之前淘汰产品。

### 5。需要一个稳定的世界

深度学习在特定环境和规则的稳定条件下工作良好，例如解决谜题或玩游戏。现实世界更加复杂、多变、千变万化。深度学习模型的实际应用应该持保留态度。目前很多 AI 产品就像初露头角的学生——需要人类的监督。

## 结论

深度学习是一种方法。支撑深度学习的统计技术和数学并没有什么固有的缺陷。像任何其他方法一样，深度学习有其优点和缺点。研究这个领域，并明智地将其作为机器学习策略的一部分。